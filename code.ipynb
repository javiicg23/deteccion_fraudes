{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Detección de fraudes"
      ],
      "metadata": {
        "id": "1XNwtSVu1Snl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BifpRJGBneDC"
      },
      "outputs": [],
      "source": [
        "# Librerías\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
        "from sklearn.metrics import (\n",
        "    average_precision_score, precision_recall_curve,\n",
        "    precision_score, recall_score, f1_score, confusion_matrix\n",
        ")\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.feature_selection import mutual_info_classif\n",
        "import itertools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "baA9aoNGjFIv"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    import xgboost as xgb\n",
        "    HAS_XGB = True\n",
        "except Exception:\n",
        "    HAS_XGB = False\n",
        "\n",
        "try:\n",
        "    import lightgbm as lgb\n",
        "    HAS_LGB = True\n",
        "except Exception:\n",
        "    HAS_LGB = False"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Análisis Exploratorio de Datos"
      ],
      "metadata": {
        "id": "txb_KKbtXvd-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cPvA3hqennw_"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/content/creditcard-train-in-.csv')\n",
        "display(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EH1eSp2x6bPQ"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hg4xXtg2RD2M"
      },
      "source": [
        "### Analisis exploratorio de train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oH6e0tFMKMYX"
      },
      "outputs": [],
      "source": [
        "# Gráfica de las clases\n",
        "plt.figure(figsize=(8, 6))\n",
        "ax = sns.countplot(x='Class', data=df, palette=['skyblue', 'red'])\n",
        "plt.title('Distribución de la clase de transacción', fontsize=16)\n",
        "plt.xlabel('Clase de transacción (0: No fraude, 1: Fraude)', fontsize=12)\n",
        "plt.ylabel('Número de transacciones', fontsize=12)\n",
        "plt.xticks(ticks=[0, 1], labels=['No Fraude', 'Fraude'])\n",
        "\n",
        "#Número por Clase\n",
        "for p in ax.patches:\n",
        "    ax.annotate(f'{p.get_height()}', (p.get_x() + p.get_width() / 2., p.get_height()),\n",
        "                ha='center', va='center', xytext=(0, 5), textcoords='offset points')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uU7eUbSsAOll"
      },
      "outputs": [],
      "source": [
        "display(df[df['Class']==0].describe().T)\n",
        "display(df[df['Class']==1].describe().T)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yvZd5Sx5Al2u"
      },
      "outputs": [],
      "source": [
        "df.hist(figsize=(20, 15))\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "62fGfV8AAJXA"
      },
      "outputs": [],
      "source": [
        "df['Class'].value_counts(normalize=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t9Lh_ML5AxWR"
      },
      "outputs": [],
      "source": [
        "df['Class'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b0t3YXb_Dwp0"
      },
      "outputs": [],
      "source": [
        "variables = df.columns.drop('Class')\n",
        "\n",
        "# Cajones con bigotes\n",
        "fig, axes = plt.subplots(9, 4, figsize=(12, 28))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for i, var in enumerate(variables):\n",
        "    sns.boxplot(data=df, x='Class', y=var, palette=['skyblue', 'red'], ax=axes[i])\n",
        "    axes[i].set_xlabel('Clase')\n",
        "    axes[i].set_ylabel(var)\n",
        "    axes[i].set_xticks(ticks=[0, 1], labels=['No Fraude', 'Fraude'])\n",
        "\n",
        "#Subplots\n",
        "for j in range(i + 1, len(axes)):\n",
        "    fig.delaxes(axes[j])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aNnJRdvh7ZCC"
      },
      "outputs": [],
      "source": [
        "#Matriz de correlación de Pearson\n",
        "correlation_matrix = df.corr()\n",
        "plt.figure(figsize=(15, 12))\n",
        "sns.heatmap(correlation_matrix, cmap='coolwarm', annot=False)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4jsiqUA6qFVG"
      },
      "outputs": [],
      "source": [
        "df.corr()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fb90966f"
      },
      "outputs": [],
      "source": [
        "#Graficos bivariados\n",
        "selected_variables = [\"Amount\", \"Time\", \"V17\", \"V14\", \"V12\", \"V10\"]\n",
        "for x_var, y_var in itertools.combinations(selected_variables, 2):\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.scatterplot(data=df, x=x_var, y=y_var, hue='Class', alpha=0.5, palette=['skyblue', 'red'])\n",
        "    plt.title(f'{x_var} vs. {y_var} por Clase')\n",
        "    plt.xlabel(x_var)\n",
        "    plt.ylabel(y_var)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VXOwQ_MlIuhy"
      },
      "outputs": [],
      "source": [
        "# Cajines con bigotes de todas las variables\n",
        "for var in df.columns:\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.boxplot(data=df, y=var)\n",
        "    plt.title(f'Box Plot of {var}')\n",
        "    plt.ylabel(var)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OyjoT-l6JPWP"
      },
      "outputs": [],
      "source": [
        "df[['Amount','Time']].hist(bins=30, figsize=(10,4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r04g-XRRMP-a"
      },
      "outputs": [],
      "source": [
        "# SUponiento que el tiempo de transacción es en segundos\n",
        "plt.figure(figsize=(8,4))\n",
        "plt.hist(df['Time']/3600, bins=24)\n",
        "plt.title(\"Distribución temporal (en horas)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76C__m4MRL9X"
      },
      "source": [
        "### Analisis exploratorio del test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MUjfX97GNUEe"
      },
      "outputs": [],
      "source": [
        "df_test = pd.read_csv('/content/creditcard-test-in-.csv')\n",
        "display(df_test.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QCu1jgF0RgC4"
      },
      "outputs": [],
      "source": [
        "df_test.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vd5AA7WXRvmc"
      },
      "outputs": [],
      "source": [
        "#Matriz de correlación\n",
        "correlation_matrix = df_test.corr()\n",
        "plt.figure(figsize=(15, 12))\n",
        "sns.heatmap(correlation_matrix, cmap='coolwarm', annot=False)\n",
        "plt.title('Correlation Matrix of Variables')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-xaJimiKR-Y3"
      },
      "outputs": [],
      "source": [
        "for var in df_test.columns:\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.boxplot(data=df, y=var)\n",
        "    plt.title(f'Box Plot of {var}')\n",
        "    plt.ylabel(var)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jj6_IJ-aSgEQ"
      },
      "source": [
        "# Selección de Características"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop(columns=['Class'])\n",
        "y = df['Class']"
      ],
      "metadata": {
        "id": "ukBYY_UvrPO1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vEA0j6-as1_i"
      },
      "source": [
        "#### Método filtro"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y84dxgzpTA6T"
      },
      "outputs": [],
      "source": [
        "mi = mutual_info_classif(X, y, random_state=42)\n",
        "mi_scores = pd.Series(mi, index=X.columns).sort_values(ascending=False)\n",
        "mi_scores.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ougZVNaWRyKi"
      },
      "source": [
        "#### Método integrado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wzVWxf0ys4Ta"
      },
      "outputs": [],
      "source": [
        "rf = RandomForestClassifier(n_estimators=200, class_weight='balanced', random_state=42)\n",
        "rf.fit(X, y)\n",
        "importances = pd.Series(rf.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
        "importances.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8erVpanR7h2"
      },
      "source": [
        "#### Método wrapper\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SZyjSUAqTlgz"
      },
      "outputs": [],
      "source": [
        "rfe = RFE(LogisticRegression(max_iter=1000, solver='liblinear'), n_features_to_select=10)\n",
        "rfe.fit(X, y)\n",
        "selected_rfe = X.columns[rfe.support_]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Leo3Y8uAxew8"
      },
      "outputs": [],
      "source": [
        "selected_rfe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YakW2A1Mv3zg"
      },
      "source": [
        "# Modelación"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XHRm1RmygZ5W"
      },
      "outputs": [],
      "source": [
        "quick_run = False\n",
        "RANDOM_STATE = 42\n",
        "\n",
        "n_splits = 3 if quick_run else 5\n",
        "rf_n_estimators = 50 if quick_run else 200\n",
        "xgb_n_estimators = 50 if quick_run else 200\n",
        "lgb_n_estimators = 50 if quick_run else 200"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1iH8M3_rgFwH"
      },
      "outputs": [],
      "source": [
        "# Calculo de métricas\n",
        "def calc_metrics(y_true, y_scores, threshold=0.5, top_k=None):\n",
        "    \"\"\"\n",
        "    Devuelve métricas: AUPRC, precision, recall, f1, confusion matrix,\n",
        "    y precision\n",
        "    y_scores: probabilidades de clase positiva.\n",
        "    \"\"\"\n",
        "    ap = average_precision_score(y_true, y_scores)\n",
        "    y_pred = (y_scores >= threshold).astype(int)\n",
        "    prec = precision_score(y_true, y_pred, zero_division=0)\n",
        "    rec = recall_score(y_true, y_pred, zero_division=0)\n",
        "    f1 = f1_score(y_true, y_pred, zero_division=0)\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    res = {\n",
        "        \"AUPRC\": ap,\n",
        "        \"threshold\": threshold,\n",
        "        \"precision\": prec,\n",
        "        \"recall\": rec,\n",
        "        \"f1\": f1,\n",
        "        \"confusion_matrix\": cm\n",
        "    }\n",
        "    if top_k is not None:\n",
        "        idx = np.argsort(y_scores)[::-1][:top_k]\n",
        "        prec_at_k = y_true.iloc[idx].sum() / float(top_k)\n",
        "        res[f\"precision{top_k}\"] = prec_at_k\n",
        "    return res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "beAzYGBMgw3i"
      },
      "outputs": [],
      "source": [
        "#Calculo de umbral mínimo tal que precision >= target_precision\n",
        "def threshold_for_precision(y_true, y_scores, target_precision=0.90):\n",
        "    precision, recall, thresholds = precision_recall_curve(y_true, y_scores)\n",
        "    mask = precision[:-1] >= target_precision\n",
        "    if mask.any():\n",
        "        cand_thresholds = thresholds[mask]\n",
        "        cand_recalls = recall[:-1][mask]\n",
        "        best_idx = np.argmax(cand_recalls)\n",
        "        return cand_thresholds[best_idx]\n",
        "    else:\n",
        "        return 1.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UNCoByvYg3wL"
      },
      "outputs": [],
      "source": [
        "#Aplicación de modelo\n",
        "def get_models():\n",
        "    models = {}\n",
        "    #Logistic Regression\n",
        "    models['Logistic'] = Pipeline([\n",
        "        ('scaler', StandardScaler()),\n",
        "        ('clf', LogisticRegression(solver='liblinear', class_weight='balanced', max_iter=500, random_state=RANDOM_STATE))\n",
        "    ])\n",
        "    #SVM\n",
        "    models['SVM'] = Pipeline([\n",
        "        ('scaler', StandardScaler()),\n",
        "        ('clf', SVC(probability=True, class_weight='balanced', random_state=RANDOM_STATE))\n",
        "    ])\n",
        "    #Decision Tree\n",
        "    models['DecisionTree'] = DecisionTreeClassifier(class_weight='balanced', random_state=RANDOM_STATE)\n",
        "    #Random Forest\n",
        "    models['RandomForest'] = RandomForestClassifier(n_estimators=rf_n_estimators, class_weight='balanced', n_jobs=-1, random_state=RANDOM_STATE)\n",
        "    #XGBoost\n",
        "    if HAS_XGB:\n",
        "        models['XGBoost'] = xgb.XGBClassifier(n_estimators=xgb_n_estimators, use_label_encoder=False, eval_metric='logloss', scale_pos_weight=1.0, random_state=RANDOM_STATE, n_jobs=-1)\n",
        "    #LightGBM\n",
        "    if HAS_LGB:\n",
        "        models['LightGBM'] = lgb.LGBMClassifier(n_estimators=lgb_n_estimators, class_weight='balanced', random_state=RANDOM_STATE, n_jobs=-1)\n",
        "    #MLP\n",
        "    models['MLP'] = Pipeline([\n",
        "        ('scaler', StandardScaler()),\n",
        "        ('clf', MLPClassifier(hidden_layer_sizes=(64,32), max_iter=200, random_state=RANDOM_STATE))\n",
        "    ])\n",
        "    return models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FUuuaz18hCBE"
      },
      "outputs": [],
      "source": [
        "def evaluate_models_cv(X, y, model_dict, n_splits=5):\n",
        "    \"\"\"\n",
        "    Realiza StratifiedKFold CV y retorna un DataFrame con métricas por modelo.\n",
        "    Además devuelve dict de listas con scores y thresholds por modelo para análisis.\n",
        "    \"\"\"\n",
        "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=RANDOM_STATE)\n",
        "    results = []\n",
        "    model_scores = {name: [] for name in model_dict}\n",
        "    for name, model in model_dict.items():\n",
        "        print(f\"\\nEvaluando modelo: {name}\")\n",
        "        fold_metrics = []\n",
        "        fold_scores = []\n",
        "        for fold, (tr_idx, val_idx) in enumerate(skf.split(X, y), 1):\n",
        "            X_tr, X_val = X.iloc[tr_idx], X.iloc[val_idx]\n",
        "            y_tr, y_val = y.iloc[tr_idx], y.iloc[val_idx]\n",
        "            model.fit(X_tr, y_tr)\n",
        "            if hasattr(model, \"predict_proba\"):\n",
        "                probs = model.predict_proba(X_val)[:,1]\n",
        "            else:\n",
        "                try:\n",
        "                    dfun = model.decision_function(X_val)\n",
        "                    probs = 1 / (1 + np.exp(-dfun))\n",
        "                except Exception:\n",
        "                    probs = model.predict(X_val)\n",
        "            ap = average_precision_score(y_val, probs)\n",
        "            # umbral para precision >= 0.90\n",
        "            thr_90 = threshold_for_precision(y_val.reset_index(drop=True), pd.Series(probs), target_precision=0.90)\n",
        "            m_default = calc_metrics(y_val.reset_index(drop=True), pd.Series(probs), threshold=0.5, top_k=100)\n",
        "            m_thr90 = calc_metrics(y_val.reset_index(drop=True), pd.Series(probs), threshold=thr_90, top_k=100)\n",
        "            fold_metrics.append({\n",
        "                \"model\": name,\n",
        "                \"fold\": fold,\n",
        "                \"AUPRC\": ap,\n",
        "                \"precision@0.5\": m_default['precision'],\n",
        "                \"recall@0.5\": m_default['recall'],\n",
        "                \"f1@0.5\": m_default['f1'],\n",
        "                \"precision@100@0.5\": m_default.get(\"precision@100\", np.nan),\n",
        "                \"threshold_for_prec90\": thr_90,\n",
        "                \"precision@thr90\": m_thr90['precision'],\n",
        "                \"recall@thr90\": m_thr90['recall'],\n",
        "                \"f1@thr90\": m_thr90['f1']\n",
        "            })\n",
        "            fold_scores.append((y_val.reset_index(drop=True), probs))\n",
        "        # promedio folds\n",
        "        dfm = pd.DataFrame(fold_metrics)\n",
        "        mean_metrics = dfm.drop(columns=['model','fold']).mean().to_dict()\n",
        "        mean_metrics.update({\"model\": name})\n",
        "        results.append(mean_metrics)\n",
        "        model_scores[name] = fold_scores\n",
        "    results_df = pd.DataFrame(results).set_index('model')\n",
        "    return results_df, model_scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sXj2Gry_hKNY"
      },
      "outputs": [],
      "source": [
        "#Variables seleccionadas\n",
        "selected_vars = ['V14','V10','V16','V4','V12','V17','V11','V3','V9']\n",
        "\n",
        "y = df['Class']\n",
        "X_full = df.drop(columns=['Class']).copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k0Nh47ydhnh-"
      },
      "outputs": [],
      "source": [
        "#Revisar variables\n",
        "selected_vars = [v for v in selected_vars if v in X_full.columns]\n",
        "X_reduced = X_full[selected_vars].copy()\n",
        "\n",
        "print(\"Tamaño features full:\", X_full.shape)\n",
        "print(\"Tamaño features reduced:\", X_reduced.shape)\n",
        "\n",
        "# -------------------------\n",
        "# Definir modelos y evaluar\n",
        "# -------------------------\n",
        "models = get_models()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Hktg1z4ehyP_"
      },
      "outputs": [],
      "source": [
        "print(\"\\n--- EVALUACIÓN con FEATURES REDUCIDAS ---\")\n",
        "results_reduced, scores_reduced = evaluate_models_cv(X_reduced, y, models, n_splits=n_splits)\n",
        "print(results_reduced.sort_values('AUPRC', ascending=False))\n",
        "\n",
        "results_reduced.to_csv(\"results_reduced_features.csv\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predicción"
      ],
      "metadata": {
        "id": "MHNTZve9a4fx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = RandomForestClassifier(\n",
        "    n_estimators=200,\n",
        "    class_weight='balanced',\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "best_model.fit(X_reduced, y)"
      ],
      "metadata": {
        "id": "NX3xlGlGbOqU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = df_test[X_reduced.columns].copy()\n",
        "\n",
        "# Predicciones\n",
        "probs_test = best_model.predict_proba(X_test)[:, 1]\n",
        "THRESHOLD_FINAL = 0.29  # según precision >= 90%\n",
        "preds_test = (probs_test >= THRESHOLD_FINAL).astype(int)\n"
      ],
      "metadata": {
        "id": "khvTVXVWbPnw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificar valores nulos\n",
        "assert not np.isnan(preds_test).any(), \"Error: hay NaN en las predicciones\"\n",
        "\n",
        "#Crear DataFrame final\n",
        "output = df_test.copy()\n",
        "output['prediction'] = preds_test\n",
        "output['probability'] = probs_test"
      ],
      "metadata": {
        "id": "hOJCNm9hbWkc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_2M6gDHcelHY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Guardar\n",
        "output.to_csv(\"creditcard_test_evaluate.csv\", index=False)\n",
        "\n",
        "print(\"creditcard_test_evaluate.csv generado correctamente.\")\n",
        "print(\"Registros:\", output.shape[0])\n",
        "print(output['prediction'].value_counts())"
      ],
      "metadata": {
        "id": "6UpewrcMbcju"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output.head()"
      ],
      "metadata": {
        "id": "xD1UjrlIphRT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filtro de transacciones\n",
        "filtered_output = output[(output['probability'] >= 0.1) & (output['probability'] <= 0.9)]\n",
        "display(filtered_output)"
      ],
      "metadata": {
        "id": "d9jiUWu1pnjX"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V5E1",
      "provenance": [],
      "collapsed_sections": [
        "mKrdcvVInLRO",
        "txb_KKbtXvd-",
        "Hg4xXtg2RD2M",
        "76C__m4MRL9X",
        "Jj6_IJ-aSgEQ",
        "vEA0j6-as1_i",
        "ougZVNaWRyKi",
        "n8erVpanR7h2",
        "YakW2A1Mv3zg",
        "MHNTZve9a4fx"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}